{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decaying isomerization\n",
    "\n",
    "The decaying isomerization process is the reversible interconversion of two isometric species $S_1$ and $S_2$ combined with the (typically much slower) decay of $S_2$ to a third spcies $S_3$:\n",
    "\n",
    "$$ S_1 \\leftrightarrows S_2 \\qquad k_\\text{forward} = c_1, k_\\text{reverse} = c_2$$\n",
    "$$ S_2 \\to S_3 \\qquad k = c_3 $$\n",
    "\n",
    "As Rathinam [Rathinam 2003] and Gillespie [Gillespie 2008] note, for appropriately chosen parameters, the decaying isomerization problem is the simplest example of a \"stiff\" problem in chemical kinetics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the reversible isomerization process $ S_1 \\leftrightarrows S_2$ alone, the random variable describing the number of $S_2$ specimens at equilibrium ($t \\to \\infty$) is:\n",
    "\n",
    "$$ P(\\# S_2 = x_2) = \\text{Binomial}\\left(\\frac{c1}{c1 + c2}; x_T\\right) (x_2) $$\n",
    "\n",
    "where $x_T$ is the total inital specimens of $S_1$ and $S_2$ combined. (Gillespie 2008)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relaxation time is defined as the characteristic time for the exponential approach of a perturbed system to its equilibrium. (The characteristic time being the time it takes for the exponential function to be reduced to a fraction $1/e$ of itself.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from reactionmodel.model import Species, Reaction, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.discover import discover_tests\n",
    "\n",
    "decaying_isomerization_tests = discover_tests('./', './decaying_isomerization', include_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(decaying_isomerization_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = Species('S1')\n",
    "S2 = Species('S2')\n",
    "S3 = Species('S3')\n",
    "\n",
    "reactions = [\n",
    "    Reaction([S1], [S2], k='c1'),\n",
    "    Reaction([S2], [S1], k='c2')\n",
    "]\n",
    "\n",
    "m = Model([S1, S2], reactions)\n",
    "\n",
    "reactions.append(\n",
    "    Reaction([S2], [S3], k='c3')\n",
    ")\n",
    "\n",
    "m_decay = Model([S1, S2, S3], reactions)\n",
    "\n",
    "p = {'c1': 1, 'c2':1}\n",
    "p_decay = {'c1': 1.0, 'c2': 2.0, 'c3': 5 * 1e-5} # gillespie 2008 figure 5\n",
    "#p_decay = {'c1': 1.0, 'c2': 2.0, 'c3': 0}\n",
    "\n",
    "t_span = [0.0, 50]\n",
    "\n",
    "initial_dictionary = {'S1': 1200, 'S2': 600, 'S3':0}\n",
    "\n",
    "ic = m_decay.make_initial_condition(initial_dictionary)\n",
    "\n",
    "def end_routine(result):\n",
    "    return m_decay.y_to_dict(result.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slow-scale stochastic simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "S12 = Species('S12')\n",
    "S3  = Species('S3')\n",
    "\n",
    "reactions = [\n",
    "    Reaction([S12], [S3], k='c1*c3/(c1+c2)')\n",
    "]\n",
    "\n",
    "m_ss = Model([S12, S3], reactions)\n",
    "\n",
    "ic_ss = m_ss.make_initial_condition({'S12': initial_dictionary['S1']+initial_dictionary['S2'], 'S3': initial_dictionary['S3']})\n",
    "\n",
    "def sample_y(y_ss, m, p):\n",
    "    y_dict = {}\n",
    "    y_ss_dict = m.y_to_dict(y_ss)\n",
    "    y_dict['S3'] = y_ss_dict['S3']\n",
    "    y_dict['S2'] = np.random.binomial(y_ss_dict['S12'], p['c1']/(p['c1'] + p['c2']))\n",
    "    y_dict['S1'] = y_ss_dict['S12'] - y_dict['S2']\n",
    "    return y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybrid.gillespie import GillespieSimulator\n",
    "\n",
    "g_ss = GillespieSimulator(\n",
    "    m_ss.get_k(parameters=p_decay, jit=True),\n",
    "    m_ss.stoichiometry(),\n",
    "    m_ss.kinetic_order(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ss_end_routine(result):\n",
    "    return sample_y(result.y, m_ss, p_decay)\n",
    "\n",
    "ss_df = pd.DataFrame(g_ss.run_simulations(1000, t_span, ic_ss, np.random.default_rng(), end_routine=ss_end_routine))\n",
    "ss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_df['S3'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybrid.parse import PreconfiguredSimulatorLoader\n",
    "\n",
    "loader = PreconfiguredSimulatorLoader.load_preconfigured('hybrid_n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_s = loader.make_simulator(\n",
    "    m_decay.get_k(parameters=p_decay, jit=True),\n",
    "    m_decay.stoichiometry(),\n",
    "    m_decay.kinetic_order(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(hc_s.run_simulations(1, t_span, ic, np.random.default_rng(), end_routine=end_routine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Oct 2024] Hybrid rounding questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in decaying_isomerization_tests:\n",
    "    _, name, parse_results, _ = t\n",
    "    if name == 'least_stiff_shortest_hybrid_cle_em_nonstoich':\n",
    "        target_test = parse_results\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = target_test.model\n",
    "s_factory = target_test.simulator_config\n",
    "s = s_factory.make_simulator_from_model(model, parameters=target_test.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.make_initial_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = s.simulate(parse_results.t.t_span, model.make_initial_condition(parse_results.initial_condition), rng=np.random.default_rng())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=13)\n",
    "ax = r.plot(m.legend())\n",
    "ax.plot(r.t_history, r.y_history.sum(axis=0))\n",
    "ax.set_ylim(0, 1850)\n",
    "ax.set_yticks(np.arange(0, 2000, 600))\n",
    "ax.axhline(1800, c='r', alpha=0.2)\n",
    "ax.set_ylabel('specimens')\n",
    "\n",
    "plt.savefig('decaying_rounding.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybrid.hybrid import HybridSimulator, FixedThresholdPartitioner\n",
    "\n",
    "h_s = HybridSimulator(\n",
    "    m_decay.get_k(parameters=p_decay, jit=True),\n",
    "    m_decay.stoichiometry(),\n",
    "    m_decay.kinetic_order(),\n",
    "    FixedThresholdPartitioner(100.0),\n",
    "    fast_scale='langevin',\n",
    "    approximate_rtot=True,\n",
    "    contrived_no_reaction_rate=20.,\n",
    "    euler_maruyama_timestep=0.01,\n",
    "    round='randomly',\n",
    ")\n",
    "\n",
    "standard_gillespie_s = GillespieSimulator(\n",
    "    m_decay.get_k(parameters=p_decay, jit=True),\n",
    "    m_decay.stoichiometry(),\n",
    "    m_decay.kinetic_order(),    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = h_s.simulate([0, 50], ic, np.random.default_rng())\n",
    "result.plot(m_decay.legend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_result = standard_gillespie_s.simulate([0, 50], ic, np.random.default_rng())\n",
    "g_result.plot(m_decay.legend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kstest\n",
    "\n",
    "cle_distribution = result.y_history[0, :]\n",
    "gillespie_dist = g_result.y_history[0, :]\n",
    "\n",
    "with_ss = False\n",
    "\n",
    "labels = ['gillespie', 'langevin']\n",
    "dists = [gillespie_dist, cle_distribution]\n",
    "ss_distribution = 1800-np.random.binomial(1800, p_decay['c1']/(p_decay['c1'] + p_decay['c2']), size=20000)\n",
    "\n",
    "if with_ss:\n",
    "    labels.append('ss')\n",
    "    dists.append(ss_distribution)\n",
    "plt.hist(dists, label=labels, density=True, bins=20)\n",
    "plt.legend(labels)\n",
    "\n",
    "print(kstest(cle_distribution, gillespie_dist))\n",
    "kstest(gillespie_dist, ss_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_one = 1800-np.random.binomial(1800, p_decay['c1']/(p_decay['c1'] + p_decay['c2']), size=20000)\n",
    "test_two = 1800-np.random.binomial(1800, p_decay['c1']/(p_decay['c1'] + p_decay['c2']), size=20000)\n",
    "\n",
    "plt.hist([test_one, test_two], label=['t1', 't2'], density=True, bins=20)\n",
    "\n",
    "kstest(test_one, test_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cle_distribution), np.mean(cle_distribution), np.var(cle_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gillespie_dist), np.mean(gillespie_dist), np.var(gillespie_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tau leaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_decay.all_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybrid.tau import TauLeapSimulator\n",
    "\n",
    "equilibrium_mask = np.array([True, True, False])\n",
    "\n",
    "t_s = TauLeapSimulator(\n",
    "    m_decay.get_k(parameters=p_decay, jit=True),\n",
    "    m_decay.stoichiometry(),\n",
    "    m_decay.kinetic_order(),\n",
    "    method='implicit',\n",
    "    epsilon=0.01,\n",
    "    equilibrium_mask=equilibrium_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_span = [0, 20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "result = t_s.simulate(t_span, ic, rng, history_length=1e8)\n",
    "np.diff(result.y_history[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(result.y_history[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot(m_decay.legend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(result.y_history[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "taus = [result.t_history[i+1] - result.t_history[i] for i in range(len(result.t_history)-1)]\n",
    "plt.hist(np.array(taus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_df = pd.DataFrame(t_s.run_simulations(120, t_span, ic, np.random.default_rng(), end_routine=end_routine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_df['S3'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest\n",
    "\n",
    "kstest(tau_df['S3'], ss_df['S3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = t_s.simulate(t_span, ic, np.random.default_rng())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot(m_decay.legend())\n",
    "result.status_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Immigration + linear death process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reactionmodel.model import Species, Reaction, Model\n",
    "from hybrid.gillespie import GillespieSimulator\n",
    "\n",
    "S1 = Species('S1')\n",
    "\n",
    "reactions = [\n",
    "    Reaction([S1], [], k='r'),\n",
    "    Reaction([], [S1], k='p')\n",
    "]\n",
    "\n",
    "m = Model([S1], reactions)\n",
    "\n",
    "p = {'r': 1, 'p':100}\n",
    "\n",
    "s = GillespieSimulator(\n",
    "    m.get_k(parameters=p, jit=True),\n",
    "    m.stoichiometry(),\n",
    "    m.kinetic_order(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "result = s.simulate([0.0, 28.0], m.make_initial_condition({'S1': 100}), np.random.default_rng())\n",
    "ax = result.plot(['Y_s'])\n",
    "ax.axhline(100, color='r', linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.hist(result.y_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "r = pd.DataFrame(data={'S': np.squeeze(result.y_history.T)})\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "ax = plt.subplot()\n",
    "x = np.arange(r.min().iloc[0], r.max().iloc[0])\n",
    "\n",
    "ax.plot([x[0] for x in r.value_counts(normalize=True).sort_index().index.to_numpy()], r.value_counts(normalize=True).sort_index().to_numpy())\n",
    "#ax = r.value_counts(normalize=True).sort_index().plot()\n",
    "\n",
    "rv = scipy.stats.poisson(p['p']/p['c1'])\n",
    "ax.plot(x, rv.pmf(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tests.discover as discover\n",
    "\n",
    "discover.discover_tests('./', include_check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple experiment idea:\n",
    "\n",
    "Let's say you have a latent reservoir of size $n$ with variance $v$. As a function of the variance in the reservoir size, how much variance is there in the time until you hit exponential growth? How much variation is there in the re-seeded latent reservoir after a phase of $R_0$ that lasts for $t$ days?\n",
    "\n",
    "=> how does this translate to your conclusions about probability of mutant emergence given a set standard?\n",
    "=> how "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
